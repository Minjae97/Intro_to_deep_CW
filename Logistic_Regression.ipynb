{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from numpy.random import rand\n",
    "from numpy import log, exp, matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainxs = np.load(\"comp0090_assignment_1_data/fashion-train-imgs.npz\")\n",
    "trainys = np.load(\"comp0090_assignment_1_data/fashion-train-labels.npz\")\n",
    "devxs   = np.load(\"comp0090_assignment_1_data/fashion-dev-imgs.npz\")\n",
    "devys   = np.load(\"comp0090_assignment_1_data/fashion-dev-labels.npz\")\n",
    "testxs  = np.load(\"comp0090_assignment_1_data/fashion-test-imgs.npz\")\n",
    "testys  = np.load(\"comp0090_assignment_1_data/fashion-test-labels.npz\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04536278, 0.27281376, 0.39046082, 0.31595101,\n",
       "        0.41006866, 0.51595101, 0.53555885, 0.51595101, 0.48457846,\n",
       "        0.6179118 , 0.53163729, 0.17085297, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00222552,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.12379415, 0.47673533, 0.63359807, 0.75908827,\n",
       "        0.77477454, 0.7669314 , 0.79830395, 0.75908827, 0.81006866,\n",
       "        0.8179118 , 0.76300984, 0.79438238, 0.77477454, 0.7551667 ,\n",
       "        0.73948042, 0.74340199, 0.88850003, 0.86889219, 0.71202944,\n",
       "        0.46104905, 0.0924216 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.82575493, 0.75908827, 0.77869611, 0.69634317, 0.60614709,\n",
       "        0.53948042, 0.56300984, 0.58653925, 0.59046082, 0.59830395,\n",
       "        0.61006866, 0.64144121, 0.62575493, 0.62183336, 0.65320591,\n",
       "        0.66889219, 0.67281376, 0.67281376, 0.70418631, 0.75908827,\n",
       "        0.81399023, 0.79046082, 0.70418631, 0.65320591, 0.40614709,\n",
       "        0.11202944, 0.        , 0.        ],\n",
       "       [0.70810787, 0.68457846, 0.58653925, 0.62183336, 0.60614709,\n",
       "        0.6179118 , 0.58653925, 0.60222552, 0.63359807, 0.64928435,\n",
       "        0.59046082, 0.52771572, 0.56300984, 0.65712748, 0.71987258,\n",
       "        0.72379415, 0.75908827, 0.68457846, 0.68457846, 0.6924216 ,\n",
       "        0.71202944, 0.73948042, 0.77477454, 0.80222552, 0.80222552,\n",
       "        0.8296765 , 0.77869611, 0.53163729],\n",
       "       [0.69634317, 0.70418631, 0.60222552, 0.62183336, 0.62575493,\n",
       "        0.62183336, 0.60222552, 0.62575493, 0.57477454, 0.53555885,\n",
       "        0.59830395, 0.66104905, 0.56300984, 0.32771572, 0.11595101,\n",
       "        0.        , 0.06497062, 0.2179118 , 0.39046082, 0.59830395,\n",
       "        0.73163729, 0.83359807, 0.73163729, 0.77869611, 0.81399023,\n",
       "        0.79830395, 0.84928435, 0.8179118 ],\n",
       "       [0.64928435, 0.74340199, 0.62575493, 0.61006866, 0.62575493,\n",
       "        0.64928435, 0.59046082, 0.52771572, 0.57477454, 0.73163729,\n",
       "        0.24144121, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07281376, 0.12771572, 0.16300984, 0.39830395,\n",
       "        0.7551667 , 0.68850003, 0.41006866],\n",
       "       [0.62183336, 0.72771572, 0.62575493, 0.61006866, 0.60614709,\n",
       "        0.63359807, 0.65712748, 0.67673533, 0.74340199, 0.90810787,\n",
       "        0.58261768, 0.2296765 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.5669314 , 0.68457846, 0.60222552, 0.6179118 , 0.62183336,\n",
       "        0.6179118 , 0.67673533, 0.75908827, 0.82575493, 0.85320591,\n",
       "        0.9669314 , 0.97085297, 0.98261768, 0.74732356, 0.58261768,\n",
       "        0.52771572, 0.44536278, 0.20222552, 0.28850003, 0.44536278,\n",
       "        0.5551667 , 0.5669314 , 0.62183336, 0.74732356, 0.83359807,\n",
       "        0.86889219, 0.7551667 , 0.62183336],\n",
       "       [0.55124513, 0.68850003, 0.62575493, 0.63359807, 0.65320591,\n",
       "        0.65320591, 0.66889219, 0.73163729, 0.7669314 , 0.7551667 ,\n",
       "        0.75908827, 0.75908827, 0.81006866, 0.84928435, 0.86104905,\n",
       "        0.83359807, 0.84536278, 0.86104905, 0.86104905, 0.84536278,\n",
       "        0.86104905, 0.87281376, 0.86497062, 0.86104905, 0.86497062,\n",
       "        0.80222552, 0.88457846, 0.80222552],\n",
       "       [0.60614709, 0.67281376, 0.60222552, 0.61006866, 0.63751964,\n",
       "        0.63359807, 0.66104905, 0.67281376, 0.67281376, 0.67673533,\n",
       "        0.67673533, 0.6924216 , 0.68850003, 0.68850003, 0.6924216 ,\n",
       "        0.71202944, 0.72771572, 0.72379415, 0.69634317, 0.70810787,\n",
       "        0.70810787, 0.70810787, 0.6924216 , 0.68457846, 0.6924216 ,\n",
       "        0.63359807, 0.51987258, 0.3551667 ],\n",
       "       [0.44536278, 0.65320591, 0.65712748, 0.60222552, 0.5669314 ,\n",
       "        0.53163729, 0.54732356, 0.59830395, 0.56300984, 0.68457846,\n",
       "        0.59046082, 0.55124513, 0.51202944, 0.50418631, 0.46104905,\n",
       "        0.41006866, 0.39830395, 0.44536278, 0.46497062, 0.39438238,\n",
       "        0.30418631, 0.27281376, 0.20222552, 0.15124513, 0.07281376,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.27673533, 0.37477454, 0.39830395,\n",
       "        0.39830395, 0.30418631, 0.18653925, 0.10810787, 0.12771572,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxs[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20250aa0c70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Fashion MNIST')\n",
    "ax1.imshow(trainxs[1:,:,0])\n",
    "ax2.imshow(trainxs[:,:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxs.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxs.shape[0] * trainxs.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x : 1/(1 + exp(-x))\n",
    "sigPrime = lambda x : sig(x)*(1 - sig(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputPar = trainxs.shape[0] * trainxs.shape[1]\n",
    "W = np.random.rand(2, inputPar)/100\n",
    "b = np.zeros(2)\n",
    "\n",
    "lr = {'W': np.random.rand(2, inputPar)/100,\n",
    "       'b': np.zeros((2, 1))}\n",
    "lr['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_lr = copy.deepcopy(lr)\n",
    "fdgrad_lr = copy.deepcopy(lr)\n",
    "diff_grad_lr = copy.deepcopy(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lambda m, x : matmul(m['W'], x) + m['b']\n",
    "f = lambda m, x : sigmoid(a(m,x))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda m, x, y: np.square(np.subtract(y,f(m, x)))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = trainxs.reshape(784, 1,12000)[:,:, 7]\n",
    "sample1y = trainys[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01814136],\n",
       "       [0.09657274],\n",
       "       [0.39461195],\n",
       "       [0.72010215],\n",
       "       [0.79461195],\n",
       "       [0.92794529],\n",
       "       [0.87696489],\n",
       "       [0.60245509],\n",
       "       [0.25735705],\n",
       "       [0.01814136],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.12794529],\n",
       "       [0.07696489],\n",
       "       [0.01814136],\n",
       "       [0.24167078],\n",
       "       [0.68088646],\n",
       "       [0.83382764],\n",
       "       [0.87304332],\n",
       "       [0.87696489],\n",
       "       [0.85735705],\n",
       "       [0.84951391],\n",
       "       [0.82990607],\n",
       "       [0.78676881],\n",
       "       [0.93186685],\n",
       "       [0.48088646],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.17108254],\n",
       "       [0.64951391],\n",
       "       [0.61814136],\n",
       "       [0.58284725],\n",
       "       [0.66127862],\n",
       "       [0.85343548],\n",
       "       [0.8142198 ],\n",
       "       [0.79069038],\n",
       "       [0.84951391],\n",
       "       [0.86127862],\n",
       "       [0.84559234],\n",
       "       [0.82990607],\n",
       "       [0.84951391],\n",
       "       [0.83774921],\n",
       "       [0.91618058],\n",
       "       [0.10441587],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.7514747 ],\n",
       "       [0.7632394 ],\n",
       "       [0.74755313],\n",
       "       [0.80245509],\n",
       "       [0.82206293],\n",
       "       [0.84951391],\n",
       "       [0.84951391],\n",
       "       [0.80245509],\n",
       "       [0.88480803],\n",
       "       [0.88480803],\n",
       "       [0.81029823],\n",
       "       [0.80637666],\n",
       "       [0.85735705],\n",
       "       [0.88088646],\n",
       "       [0.97500411],\n",
       "       [0.02990607],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.9004943 ],\n",
       "       [0.77108254],\n",
       "       [0.7632394 ],\n",
       "       [0.77108254],\n",
       "       [0.84951391],\n",
       "       [0.78284725],\n",
       "       [0.8259845 ],\n",
       "       [0.81814136],\n",
       "       [0.80245509],\n",
       "       [0.83382764],\n",
       "       [0.80637666],\n",
       "       [0.81814136],\n",
       "       [0.7514747 ],\n",
       "       [0.73578842],\n",
       "       [0.81814136],\n",
       "       [0.94755313],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.58676881],\n",
       "       [0.77892568],\n",
       "       [0.65343548],\n",
       "       [0.7004943 ],\n",
       "       [0.77500411],\n",
       "       [0.88088646],\n",
       "       [0.75539627],\n",
       "       [0.74363156],\n",
       "       [0.73186685],\n",
       "       [0.72794529],\n",
       "       [0.76716097],\n",
       "       [0.7514747 ],\n",
       "       [0.75931783],\n",
       "       [0.75931783],\n",
       "       [0.73186685],\n",
       "       [0.78676881],\n",
       "       [0.8887296 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.70441587],\n",
       "       [0.70441587],\n",
       "       [0.62206293],\n",
       "       [0.64951391],\n",
       "       [0.63382764],\n",
       "       [0.73186685],\n",
       "       [0.73186685],\n",
       "       [0.75539627],\n",
       "       [0.7632394 ],\n",
       "       [0.73970999],\n",
       "       [0.75931783],\n",
       "       [0.74363156],\n",
       "       [0.76716097],\n",
       "       [0.75539627],\n",
       "       [0.74755313],\n",
       "       [0.77500411],\n",
       "       [0.91618058],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.83382764],\n",
       "       [0.70833744],\n",
       "       [0.68088646],\n",
       "       [0.71618058],\n",
       "       [0.7004943 ],\n",
       "       [0.6887296 ],\n",
       "       [0.74363156],\n",
       "       [0.74363156],\n",
       "       [0.77500411],\n",
       "       [0.75931783],\n",
       "       [0.7632394 ],\n",
       "       [0.73578842],\n",
       "       [0.76716097],\n",
       "       [0.73970999],\n",
       "       [0.7632394 ],\n",
       "       [0.76716097],\n",
       "       [0.91618058],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.83382764],\n",
       "       [0.79069038],\n",
       "       [0.71225901],\n",
       "       [0.8142198 ],\n",
       "       [0.79853352],\n",
       "       [0.78284725],\n",
       "       [0.73970999],\n",
       "       [0.70833744],\n",
       "       [0.69265117],\n",
       "       [0.73186685],\n",
       "       [0.76716097],\n",
       "       [0.75931783],\n",
       "       [0.74755313],\n",
       "       [0.7514747 ],\n",
       "       [0.75539627],\n",
       "       [0.77500411],\n",
       "       [0.92402372],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.12402372],\n",
       "       [0.3632394 ],\n",
       "       [0.83774921],\n",
       "       [0.26520019],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.71618058],\n",
       "       [0.78284725],\n",
       "       [0.70833744],\n",
       "       [0.70441587],\n",
       "       [0.72794529],\n",
       "       [0.75931783],\n",
       "       [0.75931783],\n",
       "       [0.7514747 ],\n",
       "       [0.76716097],\n",
       "       [0.74363156],\n",
       "       [0.77892568],\n",
       "       [0.92794529],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.1514747 ],\n",
       "       [0.51225901],\n",
       "       [0.68480803],\n",
       "       [0.61029823],\n",
       "       [0.53970999],\n",
       "       [0.71225901],\n",
       "       [0.6259845 ],\n",
       "       [0.54363156],\n",
       "       [0.53186685],\n",
       "       [0.44559234],\n",
       "       [0.78676881],\n",
       "       [0.76716097],\n",
       "       [0.69657274],\n",
       "       [0.69657274],\n",
       "       [0.71225901],\n",
       "       [0.7514747 ],\n",
       "       [0.75539627],\n",
       "       [0.7514747 ],\n",
       "       [0.77108254],\n",
       "       [0.74363156],\n",
       "       [0.77892568],\n",
       "       [0.8887296 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.37108254],\n",
       "       [0.54363156],\n",
       "       [0.11225901],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.84167078],\n",
       "       [0.73970999],\n",
       "       [0.73186685],\n",
       "       [0.78676881],\n",
       "       [0.77108254],\n",
       "       [0.78676881],\n",
       "       [0.7514747 ],\n",
       "       [0.72010215],\n",
       "       [0.69657274],\n",
       "       [0.69657274],\n",
       "       [0.7514747 ],\n",
       "       [0.75539627],\n",
       "       [0.7514747 ],\n",
       "       [0.75931783],\n",
       "       [0.74755313],\n",
       "       [0.77500411],\n",
       "       [0.80637666],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.19461195],\n",
       "       [0.6259845 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.88480803],\n",
       "       [0.70833744],\n",
       "       [0.65343548],\n",
       "       [0.68088646],\n",
       "       [0.65735705],\n",
       "       [0.77108254],\n",
       "       [0.7514747 ],\n",
       "       [0.70833744],\n",
       "       [0.71618058],\n",
       "       [0.7004943 ],\n",
       "       [0.72794529],\n",
       "       [0.74755313],\n",
       "       [0.7632394 ],\n",
       "       [0.75539627],\n",
       "       [0.74363156],\n",
       "       [0.78284725],\n",
       "       [0.79853352],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.4259845 ],\n",
       "       [0.07304332],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.89265117],\n",
       "       [0.72794529],\n",
       "       [0.66912176],\n",
       "       [0.7004943 ],\n",
       "       [0.68088646],\n",
       "       [0.77108254],\n",
       "       [0.7514747 ],\n",
       "       [0.71225901],\n",
       "       [0.72010215],\n",
       "       [0.71225901],\n",
       "       [0.71618058],\n",
       "       [0.74363156],\n",
       "       [0.76716097],\n",
       "       [0.7632394 ],\n",
       "       [0.73578842],\n",
       "       [0.79069038],\n",
       "       [0.8142198 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.33970999],\n",
       "       [0.48480803],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.89265117],\n",
       "       [0.73186685],\n",
       "       [0.67304332],\n",
       "       [0.70441587],\n",
       "       [0.68480803],\n",
       "       [0.77108254],\n",
       "       [0.74363156],\n",
       "       [0.71225901],\n",
       "       [0.72402372],\n",
       "       [0.71225901],\n",
       "       [0.72402372],\n",
       "       [0.74755313],\n",
       "       [0.75931783],\n",
       "       [0.76716097],\n",
       "       [0.73970999],\n",
       "       [0.78676881],\n",
       "       [0.79461195],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.59853352],\n",
       "       [0.2887296 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.87696489],\n",
       "       [0.73186685],\n",
       "       [0.66127862],\n",
       "       [0.6887296 ],\n",
       "       [0.68088646],\n",
       "       [0.76716097],\n",
       "       [0.73970999],\n",
       "       [0.70833744],\n",
       "       [0.72794529],\n",
       "       [0.72402372],\n",
       "       [0.72794529],\n",
       "       [0.7514747 ],\n",
       "       [0.75931783],\n",
       "       [0.77108254],\n",
       "       [0.73578842],\n",
       "       [0.78676881],\n",
       "       [0.78676881],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.41814136],\n",
       "       [0.63382764],\n",
       "       [0.42206293],\n",
       "       [0.17108254],\n",
       "       [0.        ],\n",
       "       [0.74755313],\n",
       "       [0.7632394 ],\n",
       "       [0.70833744],\n",
       "       [0.76716097],\n",
       "       [0.74363156],\n",
       "       [0.79853352],\n",
       "       [0.73578842],\n",
       "       [0.7004943 ],\n",
       "       [0.73186685],\n",
       "       [0.72402372],\n",
       "       [0.72794529],\n",
       "       [0.7514747 ],\n",
       "       [0.75931783],\n",
       "       [0.77108254],\n",
       "       [0.73970999],\n",
       "       [0.79069038],\n",
       "       [0.77108254],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06127862],\n",
       "       [0.46912176],\n",
       "       [0.6887296 ],\n",
       "       [0.80245509],\n",
       "       [0.72010215],\n",
       "       [0.66127862],\n",
       "       [0.54755313],\n",
       "       [0.51225901],\n",
       "       [0.4259845 ],\n",
       "       [0.73186685],\n",
       "       [0.75539627],\n",
       "       [0.71225901],\n",
       "       [0.72794529],\n",
       "       [0.72010215],\n",
       "       [0.73186685],\n",
       "       [0.74363156],\n",
       "       [0.75931783],\n",
       "       [0.77500411],\n",
       "       [0.73970999],\n",
       "       [0.80637666],\n",
       "       [0.69657274],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.77500411],\n",
       "       [0.6887296 ],\n",
       "       [0.57500411],\n",
       "       [0.54755313],\n",
       "       [0.46127862],\n",
       "       [0.70833744],\n",
       "       [0.77892568],\n",
       "       [0.71225901],\n",
       "       [0.72794529],\n",
       "       [0.73186685],\n",
       "       [0.73970999],\n",
       "       [0.75539627],\n",
       "       [0.77108254],\n",
       "       [0.77892568],\n",
       "       [0.74363156],\n",
       "       [0.81029823],\n",
       "       [0.69657274],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.74363156],\n",
       "       [0.81029823],\n",
       "       [0.70441587],\n",
       "       [0.75539627],\n",
       "       [0.77108254],\n",
       "       [0.75931783],\n",
       "       [0.7632394 ],\n",
       "       [0.72010215],\n",
       "       [0.70833744],\n",
       "       [0.72794529],\n",
       "       [0.73578842],\n",
       "       [0.7514747 ],\n",
       "       [0.7632394 ],\n",
       "       [0.77108254],\n",
       "       [0.7514747 ],\n",
       "       [0.8142198 ],\n",
       "       [0.69657274],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.85343548],\n",
       "       [0.82990607],\n",
       "       [0.66127862],\n",
       "       [0.69657274],\n",
       "       [0.7004943 ],\n",
       "       [0.75539627],\n",
       "       [0.72402372],\n",
       "       [0.73186685],\n",
       "       [0.72402372],\n",
       "       [0.72402372],\n",
       "       [0.73970999],\n",
       "       [0.75539627],\n",
       "       [0.77108254],\n",
       "       [0.76716097],\n",
       "       [0.75539627],\n",
       "       [0.81814136],\n",
       "       [0.68480803],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04559234],\n",
       "       [0.75539627],\n",
       "       [0.77892568],\n",
       "       [0.77500411],\n",
       "       [0.71225901],\n",
       "       [0.6887296 ],\n",
       "       [0.73970999],\n",
       "       [0.72402372],\n",
       "       [0.68480803],\n",
       "       [0.72010215],\n",
       "       [0.73970999],\n",
       "       [0.73970999],\n",
       "       [0.75931783],\n",
       "       [0.7632394 ],\n",
       "       [0.78676881],\n",
       "       [0.75539627],\n",
       "       [0.8142198 ],\n",
       "       [0.72402372],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.15931783],\n",
       "       [0.81814136],\n",
       "       [0.86912176],\n",
       "       [0.76716097],\n",
       "       [0.72402372],\n",
       "       [0.76716097],\n",
       "       [0.81029823],\n",
       "       [0.81029823],\n",
       "       [0.76716097],\n",
       "       [0.77500411],\n",
       "       [0.78284725],\n",
       "       [0.7514747 ],\n",
       "       [0.77108254],\n",
       "       [0.78676881],\n",
       "       [0.73970999],\n",
       "       [0.82206293],\n",
       "       [0.75931783],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.12402372],\n",
       "       [0.87696489],\n",
       "       [0.86912176],\n",
       "       [0.79461195],\n",
       "       [0.77500411],\n",
       "       [0.79069038],\n",
       "       [0.82990607],\n",
       "       [0.84167078],\n",
       "       [0.85343548],\n",
       "       [0.89657274],\n",
       "       [0.82206293],\n",
       "       [0.8142198 ],\n",
       "       [0.79069038],\n",
       "       [0.79853352],\n",
       "       [0.8887296 ],\n",
       "       [0.84951391],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10441587],\n",
       "       [0.9004943 ],\n",
       "       [0.82990607],\n",
       "       [0.85343548],\n",
       "       [0.85735705],\n",
       "       [0.81029823],\n",
       "       [0.79069038],\n",
       "       [0.79853352],\n",
       "       [0.8259845 ],\n",
       "       [0.8142198 ],\n",
       "       [0.82990607],\n",
       "       [0.81029823],\n",
       "       [0.8142198 ],\n",
       "       [0.91225901],\n",
       "       [0.7632394 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.12794529],\n",
       "       [0.4142198 ],\n",
       "       [0.62206293],\n",
       "       [0.82990607],\n",
       "       [0.97500411],\n",
       "       [0.9514747 ],\n",
       "       [0.9514747 ],\n",
       "       [0.97500411],\n",
       "       [0.97500411],\n",
       "       [0.97500411],\n",
       "       [0.91225901],\n",
       "       [0.97500411],\n",
       "       [0.9004943 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02206293],\n",
       "       [0.1514747 ],\n",
       "       [0.18676881],\n",
       "       [0.25735705],\n",
       "       [0.17892568],\n",
       "       [0.21814136],\n",
       "       [0.35931783],\n",
       "       [0.47696489],\n",
       "       [0.06127862],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W': array([[0.00829756, 0.00778548, 0.00651337, ..., 0.00532482, 0.00363465,\n",
       "         0.00041744],\n",
       "        [0.00824018, 0.00546613, 0.0044832 , ..., 0.00962182, 0.00401487,\n",
       "         0.00019641]]),\n",
       " 'b': array([[0.],\n",
       "        [0.]])}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 784)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_lr = {'W': False,\n",
    "             'b': False,}\n",
    "\n",
    "\n",
    "lst = []\n",
    "eps = 0.0000000001\n",
    "\n",
    "for key, value in lr.items():\n",
    "    for i in range(value.shape[0]):\n",
    "        for j in range(value.shape[1]):\n",
    "            temp = value[i,j]\n",
    "            #print(temp)\n",
    "            value[i,j] += eps/2\n",
    "            r = loss(lr, sample1, trainys[0])\n",
    "            value[i,j] = temp\n",
    "            value[i,j] -= eps/2\n",
    "            l = loss(lr, sample1, trainys[0])\n",
    "            value[i,j] = temp\n",
    "            \n",
    "            fdgrad_lr[key][i,j] = (r-l)/(eps)\n",
    "\n",
    "            diff_grad_lr[key][i,j] = abs(fdgrad_lr[key][i,j] - grad_lr[key][i,j])\n",
    "            \n",
    "            if((key == 'W') and (diff_grad_lr[key][i,j] != 0)):\n",
    "                lst.append(diff_grad_lr[key][i,j])\n",
    "    check_lr[key] = (diff_grad_lr[key] < 0.05).all()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W': array([[0.        , 0.        , 0.        , ..., 0.00737799, 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]]), 'b': array([[0.12041423],\n",
      "       [0.        ]])}\n",
      "Error:  {'W': array([[0.00829756, 0.00778548, 0.00651337, ..., 0.00205317, 0.00363465,\n",
      "        0.00041744],\n",
      "       [0.00824018, 0.00546613, 0.0044832 , ..., 0.00962182, 0.00401487,\n",
      "        0.00019641]]), 'b': array([[0.12041423],\n",
      "       [0.        ]])}\n",
      "{'W': False, 'b': False}\n",
      "1568\n",
      "0.026811596766321565\n"
     ]
    }
   ],
   "source": [
    "print(fdgrad_lr)\n",
    "\n",
    "print(\"Error: \", diff_grad_lr)\n",
    "print(check_lr)\n",
    "\n",
    "print(len(lst))\n",
    "print(np.average(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample1 = trainxs.reshape(784, 1,12000)[:,:, 3000]\n",
    "sample1y = trainys[3000]\n",
    "\n",
    "inputPar = trainxs.shape[0] * trainxs.shape[1]\n",
    "hid1 = 64\n",
    "hid2 = 32\n",
    "\n",
    "#mlp = ThreeLayerPerceptron(hid1, hid2, inputPar) \n",
    "#grad_mlp = ThreeLayerPerceptron(hid1, hid2, inputPar)\n",
    "#print(mlp.W1.shape, b1.shape, W2.shape, b2.shape, W3.shape)\n",
    "\n",
    "mlp = {'W1': rand(hid1, inputPar)/100,\n",
    "       'b1': np.zeros((hid1, 1)),\n",
    "       'W2': rand(hid2, hid1)/100,\n",
    "       'b2': np.zeros((hid2, 1)),\n",
    "       'W3': rand(hid2, 1)/100,\n",
    "       'b3': np.zeros((1,1))}\n",
    "\n",
    "grad_mlp = copy.deepcopy(mlp)\n",
    "fdgrad_mlp = copy.deepcopy(mlp)\n",
    "diff_grad_mlp = copy.deepcopy(mlp)\n",
    "check_mlp = {'W1': False,\n",
    "             'b1': False,\n",
    "             'W2': False,\n",
    "             'b2': False,\n",
    "             'W3': False,\n",
    "             'b3': False}\n",
    "\n",
    "\n",
    "#print(\"W1 = \", mlp['W1'].shape)\n",
    "#print(\"b1 = \", mlp['b1'].shape)\n",
    "#print(\"W2 = \", mlp['W2'].shape)\n",
    "#print(\"b2 = \", mlp['b2'].shape)\n",
    "#print(\"W3 = \", mlp['W3'].shape)\n",
    "\n",
    "sig = lambda x : 1/(1 + exp(-x))\n",
    "sigPrime = lambda x : sig(x)*(1 - sig(x))\n",
    "\n",
    "a1 = lambda m, x : matmul(m['W1'], x) + m['b1']\n",
    "h1 = lambda m, x : sig(a1(m,x))\n",
    "a2 = lambda m, x : matmul(m['W2'], h1(m,x)) + m['b2']\n",
    "h2 = lambda m, x : sig(a2(m,x))\n",
    "a3 = lambda m, x : matmul(m['W3'].T, h2(m,x)) + m['b3'][0,0]\n",
    "f = h3 = lambda m, x : sig(a3(m,x))[0,0]\n",
    "\n",
    "loss = lambda m, x, y: -log((1 - f(m, x))**(1 - y)) - log(f(m, x)**y)\n",
    "\n",
    "#print(\"f = \", f(mlp, sample1))\n",
    "#print(\"Loss = \", loss(mlp, sample1, trainys[0]))\n",
    "\n",
    "######## Analytica Gradient of Parameters #########\n",
    "\n",
    "#grad_mlp['W3'] = (h3(mlp, sample1) - sample1y) * h2(mlp, sample1)\n",
    "#print(grad_mlp['W3'].shape)\n",
    "#grad_mlp['b3'][0,0] = (h3(mlp, sample1) - sample1y)\n",
    "#\n",
    "#grad_mlp['W2'] = (h3(mlp, sample1) - sample1y) * mlp['W3'] @ h2(mlp, sample1).T @ (1 - h2(mlp, sample1)) @ h1(mlp, sample1).T\n",
    "#print(grad_mlp['W2'].shape)\n",
    "#grad_mlp['b2'] = (h3(mlp, sample1) - sample1y) * mlp['W3'] @ h2(mlp, sample1).T @ (1 - h2(mlp, sample1))\n",
    "#\n",
    "#grad_mlp['W1'] = (((h3(mlp, sample1) - sample1y) * mlp['W3'] @ h2(mlp, sample1).T @ (1 - h2(mlp, sample1))).T @ mlp['W2']).T @ h1(mlp, sample1).T @ (1 - h1(mlp, sample1)) @ sample1.T\n",
    "#print((grad_mlp['W1'] ).shape)\n",
    "#grad_mlp['b1'] = (((h3(mlp, sample1) - sample1y) * mlp['W3'] @ h2(mlp, sample1).T @ (1 - h2(mlp, sample1))).T @  mlp['W2']).T @ h1(mlp, sample1).T @ (1 - h1(mlp, sample1))\n",
    "\n",
    "\n",
    "\n",
    "grad_mlp['b3'][0,0] = h3(mlp, sample1) - sample1y\n",
    "#print(grad_mlp['b3'][0,0])\n",
    "grad_mlp['W3'] = (h3(mlp, sample1) - sample1y) * h2(mlp, sample1)\n",
    "#print(grad_mlp['W3'].shape)\n",
    "\n",
    "grad_mlp['b2'] = grad_mlp['b3'][0,0] * h2(mlp, sample1) @ (1 - h2(mlp, sample1)).T @ mlp['W3']\n",
    "grad_mlp['W2'] = (h1(mlp, sample1) @ grad_mlp['b2'].T).T\n",
    "#print(grad_mlp['W2'].shape)\n",
    "\n",
    "grad_mlp['b1'] = h1(mlp, sample1) @ (1 - h1(mlp, sample1)).T @  mlp['W2'].T @ grad_mlp['b2']\n",
    "grad_mlp['W1'] =  (sample1 @ grad_mlp['b1'].T).T\n",
    "#print((grad_mlp['W1'] ).shape)\n",
    "\n",
    "\n",
    "#grad_mlp['b3'][0,0] = h3(mlp, sample1) - sample1y\n",
    "#print(grad_mlp['b3'][0,0])\n",
    "#grad_mlp['W3'] = (h3(mlp, sample1) - sample1y) * h2(mlp, sample1)\n",
    "#print(grad_mlp['W3'].shape)\n",
    "#\n",
    "#grad_mlp['b2'] = matmul(matmul(grad_mlp['b3'][0,0] * h2(mlp, sample1), (1 - h2(mlp, sample1)).T), mlp['W3'])\n",
    "#grad_mlp['W2'] = matmul(h1(mlp, sample1), grad_mlp['b2'].T).T\n",
    "#print(grad_mlp['W2'].shape)\n",
    "#\n",
    "#grad_mlp['b1'] = matmul(matmul(matmul(h1(mlp, sample1), (1 - h1(mlp, sample1)).T), mlp['W2'].T), grad_mlp['b2'])\n",
    "#grad_mlp['W1'] =  matmul(sample1, grad_mlp['b1'].T).T\n",
    "#print((grad_mlp['W1'] ).shape)\n",
    "\n",
    "\n",
    "######## Finite Difference Gradient of Parameters #########\n",
    "\n",
    "#temp = mlp['b3'][0]\n",
    "#mlp['b3'][0] += eps/2\n",
    "#r = loss(mlp, sample1, trainys[0])\n",
    "#mlp['b3'][0] = temp\n",
    "#mlp['b3'][0] -= eps/2\n",
    "#l = loss(mlp, sample1, trainys[0])\n",
    "#\n",
    "#res = (r-l)/eps\n",
    "#print(\"b3 = \", res)\n",
    "\n",
    "\n",
    "#pars = [mlp.W1, mlp.b1, mlp.W2, mlp.b2, mlp.W3, [mlp.b3]]\n",
    "lst = []\n",
    "eps = 0.0000000001\n",
    "for key, par in mlp.items():\n",
    "    for i in range(par.shape[0]):\n",
    "        for j in range(par.shape[1]):\n",
    "            temp = par[i,j]\n",
    "            #print(temp)\n",
    "            par[i,j] += eps/2\n",
    "            r = loss(mlp, sample1, trainys[0])\n",
    "            par[i,j] = temp\n",
    "            par[i,j] -= eps/2\n",
    "            l = loss(mlp, sample1, trainys[0])\n",
    "            par[i,j] = temp\n",
    "            \n",
    "            fdgrad_mlp[key][i,j] = (r-l)/(2*eps)\n",
    "\n",
    "            diff_grad_mlp[key][i,j] = abs(fdgrad_mlp[key][i,j] - grad_mlp[key][i,j])\n",
    "            \n",
    "            if((key == 'W1') and (diff_grad_mlp[key][i,j] != 0)):\n",
    "                lst.append(diff_grad_mlp[key][i,j])\n",
    "    check_mlp[key] = (diff_grad_mlp[key] < 0.05).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), 'b1': array([[1.05471187e-05],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [9.43689571e-06],\n",
      "       [1.05471187e-05],\n",
      "       [1.16573418e-05],\n",
      "       [1.05471187e-05],\n",
      "       [9.43689571e-06],\n",
      "       [8.32667268e-06],\n",
      "       [8.32667268e-06],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [9.43689571e-06],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [1.16573418e-05],\n",
      "       [9.43689571e-06],\n",
      "       [9.43689571e-06],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [9.43689571e-06],\n",
      "       [1.05471187e-05],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [9.43689571e-06],\n",
      "       [9.43689571e-06],\n",
      "       [8.32667268e-06],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [9.43689571e-06],\n",
      "       [8.32667268e-06],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [1.16573418e-05],\n",
      "       [1.05471187e-05],\n",
      "       [1.16573418e-05],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [9.43689571e-06],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [8.32667268e-06],\n",
      "       [8.32667268e-06],\n",
      "       [8.32667268e-06],\n",
      "       [1.05471187e-05],\n",
      "       [1.05471187e-05]]), 'W2': array([[1.13797860e-04, 1.16018306e-04, 1.18238752e-04, ...,\n",
      "        1.13797860e-04, 1.16018306e-04, 1.18238752e-04],\n",
      "       [3.20299343e-04, 3.28070904e-04, 3.31956684e-04, ...,\n",
      "        3.20299343e-04, 3.24740235e-04, 3.31956684e-04],\n",
      "       [1.49880108e-04, 1.52100554e-04, 1.54321000e-04, ...,\n",
      "        1.49880108e-04, 1.50990331e-04, 1.54321000e-04],\n",
      "       ...,\n",
      "       [7.99360578e-05, 8.32667268e-05, 8.32667268e-05, ...,\n",
      "        7.99360578e-05, 8.21565038e-05, 8.32667268e-05],\n",
      "       [3.13082893e-04, 3.20299343e-04, 3.23630012e-04, ...,\n",
      "        3.13082893e-04, 3.15303339e-04, 3.23630012e-04],\n",
      "       [2.09832152e-04, 2.14828155e-04, 2.17048601e-04, ...,\n",
      "        2.09832152e-04, 2.12052598e-04, 2.17048601e-04]]), 'b2': array([[1.55431223e-04],\n",
      "       [4.37427872e-04],\n",
      "       [2.02060590e-04],\n",
      "       [5.21804822e-04],\n",
      "       [5.77871084e-04],\n",
      "       [1.93733918e-04],\n",
      "       [2.20379270e-04],\n",
      "       [6.18394225e-04],\n",
      "       [1.27675648e-04],\n",
      "       [2.23709939e-04],\n",
      "       [2.37587727e-04],\n",
      "       [3.25850458e-04],\n",
      "       [2.42583731e-04],\n",
      "       [4.19664303e-04],\n",
      "       [7.99360578e-05],\n",
      "       [4.64073224e-04],\n",
      "       [6.41708908e-04],\n",
      "       [1.63757896e-04],\n",
      "       [5.54556401e-04],\n",
      "       [1.23234756e-04],\n",
      "       [1.21569421e-04],\n",
      "       [5.69544412e-04],\n",
      "       [2.59792188e-04],\n",
      "       [1.83186799e-04],\n",
      "       [3.75810494e-04],\n",
      "       [2.17048601e-04],\n",
      "       [9.15933995e-05],\n",
      "       [4.53526106e-04],\n",
      "       [2.37587727e-04],\n",
      "       [1.11577414e-04],\n",
      "       [4.25770530e-04],\n",
      "       [2.85327317e-04]]), 'W3': array([[0.14700741],\n",
      "       [0.14529211],\n",
      "       [0.14580226],\n",
      "       [0.14552304],\n",
      "       [0.14591828],\n",
      "       [0.14546142],\n",
      "       [0.14583001],\n",
      "       [0.145714  ],\n",
      "       [0.14427015],\n",
      "       [0.14590551],\n",
      "       [0.14713508],\n",
      "       [0.14465762],\n",
      "       [0.14526158],\n",
      "       [0.14582113],\n",
      "       [0.14690416],\n",
      "       [0.14502954],\n",
      "       [0.14481305],\n",
      "       [0.1458661 ],\n",
      "       [0.14449719],\n",
      "       [0.14566404],\n",
      "       [0.14596102],\n",
      "       [0.14852342],\n",
      "       [0.14647172],\n",
      "       [0.14765855],\n",
      "       [0.14630241],\n",
      "       [0.1451389 ],\n",
      "       [0.1467837 ],\n",
      "       [0.14716894],\n",
      "       [0.1458722 ],\n",
      "       [0.14502288],\n",
      "       [0.14506119],\n",
      "       [0.14623636]]), 'b3': array([[0.26072811]])}\n",
      "Error:  {'W1': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), 'b1': array([[0.03750944],\n",
      "       [0.03832421],\n",
      "       [0.03874623],\n",
      "       [0.0387582 ],\n",
      "       [0.03798889],\n",
      "       [0.03841661],\n",
      "       [0.03725708],\n",
      "       [0.03807542],\n",
      "       [0.03830406],\n",
      "       [0.03814872],\n",
      "       [0.03801365],\n",
      "       [0.03795709],\n",
      "       [0.03825092],\n",
      "       [0.03813221],\n",
      "       [0.03830543],\n",
      "       [0.03874079],\n",
      "       [0.03853599],\n",
      "       [0.03764276],\n",
      "       [0.03810285],\n",
      "       [0.03835262],\n",
      "       [0.03796978],\n",
      "       [0.03864557],\n",
      "       [0.03822391],\n",
      "       [0.03831143],\n",
      "       [0.03755936],\n",
      "       [0.03847554],\n",
      "       [0.03890978],\n",
      "       [0.03807148],\n",
      "       [0.03753163],\n",
      "       [0.03786407],\n",
      "       [0.03777875],\n",
      "       [0.03814399],\n",
      "       [0.03852333],\n",
      "       [0.03839817],\n",
      "       [0.03825944],\n",
      "       [0.03751963],\n",
      "       [0.03827049],\n",
      "       [0.03818262],\n",
      "       [0.03847117],\n",
      "       [0.03852046],\n",
      "       [0.03755872],\n",
      "       [0.0381289 ],\n",
      "       [0.03802678],\n",
      "       [0.03822911],\n",
      "       [0.03850963],\n",
      "       [0.03868185],\n",
      "       [0.03841112],\n",
      "       [0.03830234],\n",
      "       [0.03830669],\n",
      "       [0.03869639],\n",
      "       [0.03780367],\n",
      "       [0.03849305],\n",
      "       [0.03835353],\n",
      "       [0.03812744],\n",
      "       [0.03755434],\n",
      "       [0.0380328 ],\n",
      "       [0.0382053 ],\n",
      "       [0.03814187],\n",
      "       [0.0383143 ],\n",
      "       [0.03828596],\n",
      "       [0.03832509],\n",
      "       [0.03747985],\n",
      "       [0.0379099 ],\n",
      "       [0.03873617]]), 'W2': array([[0.01448935, 0.01480425, 0.01496542, ..., 0.01447697, 0.014643  ,\n",
      "        0.01496237],\n",
      "       [0.01411242, 0.01441806, 0.01457566, ..., 0.01410018, 0.01426202,\n",
      "        0.01457265],\n",
      "       [0.01433357, 0.01464587, 0.0148057 , ..., 0.01432129, 0.01448705,\n",
      "        0.01480267],\n",
      "       ...,\n",
      "       [0.01432613, 0.01463564, 0.01479683, ..., 0.01431392, 0.01447767,\n",
      "        0.01479382],\n",
      "       [0.01409681, 0.01440252, 0.01456042, ..., 0.0140846 , 0.0142484 ,\n",
      "        0.01455741],\n",
      "       [0.01431667, 0.01462713, 0.01478744, ..., 0.01430435, 0.01446949,\n",
      "        0.0147844 ]]), 'b2': array([[0.01973287],\n",
      "       [0.01921876],\n",
      "       [0.01952322],\n",
      "       [0.01916569],\n",
      "       [0.01916311],\n",
      "       [0.01948535],\n",
      "       [0.0195088 ],\n",
      "       [0.01909509],\n",
      "       [0.01939029],\n",
      "       [0.0195156 ],\n",
      "       [0.01966792],\n",
      "       [0.01924445],\n",
      "       [0.01940954],\n",
      "       [0.01930814],\n",
      "       [0.01979442],\n",
      "       [0.01915664],\n",
      "       [0.01894976],\n",
      "       [0.01957025],\n",
      "       [0.01899433],\n",
      "       [0.01958338],\n",
      "       [0.01962517],\n",
      "       [0.01952389],\n",
      "       [0.01955593],\n",
      "       [0.01979313],\n",
      "       [0.01941714],\n",
      "       [0.0194184 ],\n",
      "       [0.01976638],\n",
      "       [0.01945657],\n",
      "       [0.01949715],\n",
      "       [0.01950832],\n",
      "       [0.01919934],\n",
      "       [0.01949858]]), 'W3': array([[0.14700699],\n",
      "       [0.14529091],\n",
      "       [0.14580218],\n",
      "       [0.14552281],\n",
      "       [0.14591831],\n",
      "       [0.14546002],\n",
      "       [0.14583202],\n",
      "       [0.14571607],\n",
      "       [0.1442695 ],\n",
      "       [0.14590627],\n",
      "       [0.14713364],\n",
      "       [0.14465565],\n",
      "       [0.14526135],\n",
      "       [0.14582064],\n",
      "       [0.14690413],\n",
      "       [0.14502909],\n",
      "       [0.14481315],\n",
      "       [0.14586733],\n",
      "       [0.1444996 ],\n",
      "       [0.1456645 ],\n",
      "       [0.14596068],\n",
      "       [0.14852355],\n",
      "       [0.14646965],\n",
      "       [0.14765698],\n",
      "       [0.14630235],\n",
      "       [0.14513754],\n",
      "       [0.14678232],\n",
      "       [0.14716765],\n",
      "       [0.14587202],\n",
      "       [0.14502359],\n",
      "       [0.14506236],\n",
      "       [0.14623483]]), 'b3': array([[0.26072624]])}\n",
      "{'W1': True, 'b1': True, 'W2': True, 'b2': True, 'W3': False, 'b3': False}\n",
      "20800\n",
      "0.025705097712666037\n"
     ]
    }
   ],
   "source": [
    "print(fdgrad_mlp)\n",
    "\n",
    "print(\"Error: \", diff_grad_mlp)\n",
    "print(check_mlp)\n",
    "\n",
    "print(len(lst))\n",
    "print(np.average(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3.3, 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression(x, y):\n",
    "    #W = np.zeros(2, inputPar)\n",
    "    #b = np.zeros(2)\n",
    "    inputPar = trainxs.shape[0] * trainxs.shape[1]\n",
    "    W = np.zeros([2, inputPar])\n",
    "    b = np.zeros(2)\n",
    "    learningrate = 0.01\n",
    "    precision = 0.00001\n",
    "    previousstepsize = 1.0\n",
    "    n = len(x)\n",
    "    curx = 0\n",
    "    \n",
    "    while (previousstepsize > precision):\n",
    "        y_pred = sigmoid(matmul(W, x) + b)\n",
    "        D_w = -(1/n) * sum(x * (y - y_pred) * (y_pred) * (1-y_pred))\n",
    "        \n",
    "        W = W - learningrate * D_w\n",
    "        previousstepsize = abs(curx - W)\n",
    "        curx = W;\n",
    "    return W;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LogisticRegression(trainxs[:,:],trainys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros((1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.1308131 , 0.08962205, ..., 0.04505032,\n",
       "         0.        , 0.0014855 ]],\n",
       "\n",
       "       [[0.        , 0.1308131 , 0.08962205, ..., 0.04505032,\n",
       "         0.        , 0.0014855 ]],\n",
       "\n",
       "       [[0.        , 0.1308131 , 0.08962205, ..., 0.04505032,\n",
       "         0.        , 0.0014855 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.1308131 , 0.08962205, ..., 0.04505032,\n",
       "         0.        , 0.0014855 ]],\n",
       "\n",
       "       [[0.        , 0.1308131 , 0.08962205, ..., 0.04505032,\n",
       "         0.        , 0.0014855 ]],\n",
       "\n",
       "       [[0.        , 0.1308131 , 0.08962205, ..., 0.04505032,\n",
       "         0.        , 0.0014855 ]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxs.reshape(trainxs.shape[0]*trainxs.shape[1], 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResults(epochsloss_train, loss_val, acc_train, acc_val, max_val_acc_epoch):\n",
    "    print('The accuracy on the training and validation set, for the epoch on which we get the highest accuracy on the validation set is: {} / {} at epoch {}.'.format(acc_train[max_val_acc_epoch], acc_val[max_val_acc_epoch], max_val_acc_epoch+1))   \n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.suptitle(\"Loss and Accuracy Results of Training and Validation set\", fontsize = 16)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(epochs), loss_train, label=\"Training Loss\")\n",
    "    plt.plot(range(epochs), loss_val, label=\"Validation Loss\")\n",
    "    plt.xlabel('Epoch', fontsize = 13)\n",
    "    plt.ylabel('Loss', fontsize = 13)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(epochs), acc_train, label=\"Training Accuracy\")\n",
    "    plt.plot(range(epochs), acc_val, label=\"Validation Accuracy\")\n",
    "    plt.xlabel('Epoch', fontsize = 13)\n",
    "    plt.ylabel('Accuracy', fontsize = 13)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffleIdx(n):\n",
    "    rng = default_rng()\n",
    "    rand_idx = rng.permutation(n)\n",
    "    return rand_idx\n",
    "\n",
    "############################IMPORTANT PARAMETERS#############################\n",
    "batch_size = 32\n",
    "momentum = 1.0\n",
    "patience = 10 #Parameter for early_stop, 10 means wait for 10 more epochs before stop, suggest 10 for stochastic but 5 for others\n",
    "hidden = 64  #Hidden layer neurons\n",
    "###################################\n",
    "\n",
    "inputPar = trainxs.shape[0] * trainxs.shape[1]\n",
    "mlp = {'W': np.random.rand(1, inputPar)/100,\n",
    "       'b': np.zeros((1, 1))}\n",
    "\n",
    "keys = iter(mlp)\n",
    "layers_sizes = [inputPar, 1]\n",
    "\n",
    "for s in range(len(layers_sizes)-1):\n",
    "    key = next(keys)\n",
    "    epsilon = 4.0 * np.sqrt(6) / np.sqrt(layers_sizes[s] + layers_sizes[s+1])\n",
    "    mlp[key] = epsilon * ( (rand(layers_sizes[s+1], layers_sizes[s]) * 2.0 ) - 1)\n",
    "#     print(key)\n",
    "#     print(epsilon)\n",
    "#     print(mlp[key])\n",
    "\n",
    "grad_mlp = copy.deepcopy(mlp)\n",
    "\n",
    "sig = lambda x : 1/(1 + exp(-x))\n",
    "sigPrime = lambda x : sig(x)*(1 - sig(x))\n",
    "\n",
    "a1 = lambda m, x : matmul(m['W1'], x) + m['b1'][0,0]\n",
    "f = h1 = lambda m, x : sig(a1(m,x))[0,0]\n",
    "\n",
    "loss = lambda m, x, y: (x * (y - f(m, x)) * (f(m, x)) * (1-f(m, x)))\n",
    "\n",
    "\n",
    "########### LEARNING PROCESS ################\n",
    "#epoch = 500\n",
    "learning_rate = 0.01\n",
    "trainysprime = []\n",
    "# tlosslist_train = []\n",
    "# tlosslist_val = []\n",
    "# tacclist_train = []\n",
    "# tacclist_val = []\n",
    "best = 0\n",
    "patience_cnt = 0\n",
    "\n",
    "\n",
    "\n",
    "loss_train_list = []\n",
    "loss_val_list = []\n",
    "acc_train_list = []\n",
    "acc_val_list = []\n",
    "max_val_acc_epoch = 0\n",
    "n_samples = trainxs.shape[2]\n",
    "n_samples_val = devxs.shape[2]\n",
    "\n",
    "for e in range(epoch):\n",
    "    idx = shuffleIdx(X.shape[2])\n",
    "    X = trainxs[:, :, idx]\n",
    "    Y = trainys[idx]\n",
    "    \n",
    "    X_val = devxs[:,:,idx]\n",
    "    Y_val = devys[:,:,idx]\n",
    "    \n",
    "    tloss_train = 0\n",
    "    tloss_val = 0\n",
    "    \n",
    "    tacc_train = 0\n",
    "    tacc_val = 0\n",
    "    tr_true = 0\n",
    "    val_true = 0\n",
    "    cnt = 1\n",
    "    \n",
    "    total_grad = {'W': np.zeros((1, inputPar)),\n",
    "             'b': np.zeros((1, 1)),}\n",
    "    \n",
    "    # UPDATING GRADIENTS FOR EACH IMAGE IN THE TRAINING DATASET\n",
    "    for i in range(trainxs.shape[2]): #number of data\n",
    "#         x = train_data[i][0].reshape(784, 1)\n",
    "#         x = normalize(x)\n",
    "#         y = train_data[i][1]\n",
    "        x = X[:, :, i]\n",
    "        y = Y[i]\n",
    "        \n",
    "        if f(mlp,x) >= 0.5:\n",
    "            yprime = 1\n",
    "        else:\n",
    "            yprime = 0\n",
    "            \n",
    "        if yprime == y:\n",
    "            tr_true += 1\n",
    "            \n",
    "        trainysprime.append(yprime)\n",
    "        tloss_train += loss(mlp,x,y)\n",
    "        tacc_train += f(mlp,x)\n",
    "        \n",
    "        grad_mlp['b'][0,0] = h1(mlp, x) - y\n",
    "        grad_mlp['W'] = h1(mlp, x).T * grad_mlp['b']\n",
    "        \n",
    "\n",
    "        # SUMMING THE GRADIENTS OF X\n",
    "        for key in mlp:\n",
    "            tgrad[key] += grad_mlp[key]\n",
    "            \n",
    "            \n",
    "        \n",
    "#         #Mini gradient descent\n",
    "#         if cnt == batch_size:\n",
    "#             for key in tgrad:\n",
    "#                 tgrad[key] = tgrad[key]/batch_size\n",
    "#                 mlp[key] = momentum*mlp[key] - lr*tgrad[key] #With momenum\n",
    "#             cnt = 1\n",
    "#         else:\n",
    "#             cnt+=1\n",
    "                \n",
    "            \n",
    "    for j in range(devxs.shape[2]): #number of data\n",
    "        x_val = X_val[:,:,i]\n",
    "        y_val = Y_val[i]\n",
    "                    \n",
    "        if f(mlp,val_x) >= 0.5:\n",
    "            yprime = 1\n",
    "        else:\n",
    "            yprime = 0\n",
    "            \n",
    "        if yprime == val_y:\n",
    "            val_true += 1\n",
    "            \n",
    "        tloss_val += loss(mlp,val_x,val_y)\n",
    "        tacc_val  += f(mlp,val_x)\n",
    "            \n",
    "    # FINDING THE AVERAGE OF GRADIENTS FOR EACH EPOCH SINCE WE ARE DOING FULL-BATCH GRADIENT DESCEND        \n",
    "    # AND UPDATING THE PARAMETERS AFTER EACH EPOCH\n",
    "    tloss_train = tloss_train/n_samples\n",
    "    loss_train_list.append(tloss_train)\n",
    "    \n",
    "    #tacc_train = tacc_train/n_samp\n",
    "    tloss_val = tloss_val/(n_samples_val)\n",
    "    loss_val_list.append(tloss_val)\n",
    "    \n",
    "    tr_true = tr_true/n_samples_val\n",
    "    val_true = val_true/(n_samples_val)\n",
    "    \n",
    "    #tacc_val = tacc_val/(devxs.shape[2])\n",
    "    acc_train_list.append(tr_true)\n",
    "    acc_val_list.append(val_true)\n",
    "    \n",
    "#     #EarlyStopping\n",
    "#     if e == 1:\n",
    "#         best = tloss_val\n",
    "#     else:\n",
    "#         best,patience_cnt = early_stop(best, tloss_val,patience_cnt)\n",
    "#     if patience_cnt == patience:\n",
    "#         print(\"Stopped by Early stopping\")\n",
    "#         print(\"Best validation loss: {}\".format(best))\n",
    "#         print(\"Trained epochs: {}\".format(e))\n",
    "#         break\n",
    "\n",
    "    if  acc_val > acc_val_list[max_val_acc_epoch]:\n",
    "        max_val_acc_epoch = e\n",
    "\n",
    " \n",
    "    print(\"- Loss on Training / Validation Data at Epoch {}: {:.4f} / {:.4f}\".format(e+1, tloss_train, tloss_val)) \n",
    "    print(\"- Accuracy on Training / Validation Data at Epoch {}: {} / {}\\n\".format(e+1, tr_true, val_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(m, x)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(m, x)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
